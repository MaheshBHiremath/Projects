{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>cap-color</th>\n",
       "      <th>bruises</th>\n",
       "      <th>odor</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-size</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>stalk-shape</th>\n",
       "      <th>stalk-root</th>\n",
       "      <th>stalk-surface-above-ring</th>\n",
       "      <th>stalk-surface-below-ring</th>\n",
       "      <th>stalk-color-above-ring</th>\n",
       "      <th>stalk-color-below-ring</th>\n",
       "      <th>veil-color</th>\n",
       "      <th>ring-number</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>spore-print-color</th>\n",
       "      <th>population</th>\n",
       "      <th>habitat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>p</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>n</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>k</td>\n",
       "      <td>e</td>\n",
       "      <td>e</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>e</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>y</td>\n",
       "      <td>t</td>\n",
       "      <td>a</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>k</td>\n",
       "      <td>e</td>\n",
       "      <td>c</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>e</td>\n",
       "      <td>b</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>l</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>e</td>\n",
       "      <td>c</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>p</td>\n",
       "      <td>x</td>\n",
       "      <td>y</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>e</td>\n",
       "      <td>e</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>e</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>g</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>w</td>\n",
       "      <td>b</td>\n",
       "      <td>k</td>\n",
       "      <td>t</td>\n",
       "      <td>e</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>a</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8119</td>\n",
       "      <td>e</td>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>y</td>\n",
       "      <td>e</td>\n",
       "      <td>NaN</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>b</td>\n",
       "      <td>c</td>\n",
       "      <td>l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8120</td>\n",
       "      <td>e</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>y</td>\n",
       "      <td>e</td>\n",
       "      <td>NaN</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>n</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>b</td>\n",
       "      <td>v</td>\n",
       "      <td>l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8121</td>\n",
       "      <td>e</td>\n",
       "      <td>f</td>\n",
       "      <td>s</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>e</td>\n",
       "      <td>NaN</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>b</td>\n",
       "      <td>c</td>\n",
       "      <td>l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8122</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>y</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>b</td>\n",
       "      <td>t</td>\n",
       "      <td>NaN</td>\n",
       "      <td>s</td>\n",
       "      <td>k</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>e</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8123</td>\n",
       "      <td>e</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>y</td>\n",
       "      <td>e</td>\n",
       "      <td>NaN</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>o</td>\n",
       "      <td>c</td>\n",
       "      <td>l</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8124 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     class cap-shape cap-surface cap-color bruises odor gill-attachment  \\\n",
       "0        p         x           s         n       t    p               f   \n",
       "1        e         x           s         y       t    a               f   \n",
       "2        e         b           s         w       t    l               f   \n",
       "3        p         x           y         w       t    p               f   \n",
       "4        e         x           s         g       f    n               f   \n",
       "...    ...       ...         ...       ...     ...  ...             ...   \n",
       "8119     e         k           s         n       f    n               a   \n",
       "8120     e         x           s         n       f    n               a   \n",
       "8121     e         f           s         n       f    n               a   \n",
       "8122     p         k           y         n       f    y               f   \n",
       "8123     e         x           s         n       f    n               a   \n",
       "\n",
       "     gill-spacing gill-size gill-color stalk-shape stalk-root  \\\n",
       "0               c         n          k           e          e   \n",
       "1               c         b          k           e          c   \n",
       "2               c         b          n           e          c   \n",
       "3               c         n          n           e          e   \n",
       "4               w         b          k           t          e   \n",
       "...           ...       ...        ...         ...        ...   \n",
       "8119            c         b          y           e        NaN   \n",
       "8120            c         b          y           e        NaN   \n",
       "8121            c         b          n           e        NaN   \n",
       "8122            c         n          b           t        NaN   \n",
       "8123            c         b          y           e        NaN   \n",
       "\n",
       "     stalk-surface-above-ring stalk-surface-below-ring stalk-color-above-ring  \\\n",
       "0                           s                        s                      w   \n",
       "1                           s                        s                      w   \n",
       "2                           s                        s                      w   \n",
       "3                           s                        s                      w   \n",
       "4                           s                        s                      w   \n",
       "...                       ...                      ...                    ...   \n",
       "8119                        s                        s                      o   \n",
       "8120                        s                        s                      o   \n",
       "8121                        s                        s                      o   \n",
       "8122                        s                        k                      w   \n",
       "8123                        s                        s                      o   \n",
       "\n",
       "     stalk-color-below-ring veil-color ring-number ring-type  \\\n",
       "0                         w          w           o         p   \n",
       "1                         w          w           o         p   \n",
       "2                         w          w           o         p   \n",
       "3                         w          w           o         p   \n",
       "4                         w          w           o         e   \n",
       "...                     ...        ...         ...       ...   \n",
       "8119                      o          o           o         p   \n",
       "8120                      o          n           o         p   \n",
       "8121                      o          o           o         p   \n",
       "8122                      w          w           o         e   \n",
       "8123                      o          o           o         p   \n",
       "\n",
       "     spore-print-color population habitat  \n",
       "0                    k          s       u  \n",
       "1                    n          n       g  \n",
       "2                    n          n       m  \n",
       "3                    k          s       u  \n",
       "4                    n          a       g  \n",
       "...                ...        ...     ...  \n",
       "8119                 b          c       l  \n",
       "8120                 b          v       l  \n",
       "8121                 b          c       l  \n",
       "8122                 w          v       l  \n",
       "8123                 o          c       l  \n",
       "\n",
       "[8124 rows x 22 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('mushrooms.csv',na_values='?')\n",
    "pd.set_option('display.max_columns',100)\n",
    "df=df.drop(columns='veil-type')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class                          0\n",
       "cap-shape                      0\n",
       "cap-surface                    0\n",
       "cap-color                      0\n",
       "bruises                        0\n",
       "odor                           0\n",
       "gill-attachment                0\n",
       "gill-spacing                   0\n",
       "gill-size                      0\n",
       "gill-color                     0\n",
       "stalk-shape                    0\n",
       "stalk-root                  2480\n",
       "stalk-surface-above-ring       0\n",
       "stalk-surface-below-ring       0\n",
       "stalk-color-above-ring         0\n",
       "stalk-color-below-ring         0\n",
       "veil-color                     0\n",
       "ring-number                    0\n",
       "ring-type                      0\n",
       "spore-print-color              0\n",
       "population                     0\n",
       "habitat                        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class                       object\n",
       "cap-shape                   object\n",
       "cap-surface                 object\n",
       "cap-color                   object\n",
       "bruises                     object\n",
       "odor                        object\n",
       "gill-attachment             object\n",
       "gill-spacing                object\n",
       "gill-size                   object\n",
       "gill-color                  object\n",
       "stalk-shape                 object\n",
       "stalk-root                  object\n",
       "stalk-surface-above-ring    object\n",
       "stalk-surface-below-ring    object\n",
       "stalk-color-above-ring      object\n",
       "stalk-color-below-ring      object\n",
       "veil-color                  object\n",
       "ring-number                 object\n",
       "ring-type                   object\n",
       "spore-print-color           object\n",
       "population                  object\n",
       "habitat                     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['class', 'cap-shape', 'cap-surface', 'cap-color', 'bruises', 'odor',\n",
      "       'gill-attachment', 'gill-spacing', 'gill-size', 'gill-color',\n",
      "       'stalk-shape', 'stalk-root', 'stalk-surface-above-ring',\n",
      "       'stalk-surface-below-ring', 'stalk-color-above-ring',\n",
      "       'stalk-color-below-ring', 'veil-color', 'ring-number', 'ring-type',\n",
      "       'spore-print-color', 'population', 'habitat'],\n",
      "      dtype='object')\n",
      "[[class\n",
      "e    e\n",
      "p    p\n",
      "Name: class, dtype: object], [cap-shape\n",
      "b    b\n",
      "c    c\n",
      "f    f\n",
      "k    k\n",
      "s    s\n",
      "x    x\n",
      "Name: cap-shape, dtype: object], [cap-surface\n",
      "f    f\n",
      "g    g\n",
      "s    s\n",
      "y    y\n",
      "Name: cap-surface, dtype: object], [cap-color\n",
      "b    b\n",
      "c    c\n",
      "e    e\n",
      "g    g\n",
      "n    n\n",
      "p    p\n",
      "r    r\n",
      "u    u\n",
      "w    w\n",
      "y    y\n",
      "Name: cap-color, dtype: object], [bruises\n",
      "f    f\n",
      "t    t\n",
      "Name: bruises, dtype: object], [odor\n",
      "a    a\n",
      "c    c\n",
      "f    f\n",
      "l    l\n",
      "m    m\n",
      "n    n\n",
      "p    p\n",
      "s    s\n",
      "y    y\n",
      "Name: odor, dtype: object], [gill-attachment\n",
      "a    a\n",
      "f    f\n",
      "Name: gill-attachment, dtype: object], [gill-spacing\n",
      "c    c\n",
      "w    w\n",
      "Name: gill-spacing, dtype: object], [gill-size\n",
      "b    b\n",
      "n    n\n",
      "Name: gill-size, dtype: object], [gill-color\n",
      "b    b\n",
      "e    e\n",
      "g    g\n",
      "h    h\n",
      "k    k\n",
      "n    n\n",
      "o    o\n",
      "p    p\n",
      "r    r\n",
      "u    u\n",
      "w    w\n",
      "y    y\n",
      "Name: gill-color, dtype: object], [stalk-shape\n",
      "e    e\n",
      "t    t\n",
      "Name: stalk-shape, dtype: object], [stalk-root\n",
      "b    b\n",
      "c    c\n",
      "e    e\n",
      "r    r\n",
      "Name: stalk-root, dtype: object], [stalk-surface-above-ring\n",
      "f    f\n",
      "k    k\n",
      "s    s\n",
      "y    y\n",
      "Name: stalk-surface-above-ring, dtype: object], [stalk-surface-below-ring\n",
      "f    f\n",
      "k    k\n",
      "s    s\n",
      "y    y\n",
      "Name: stalk-surface-below-ring, dtype: object], [stalk-color-above-ring\n",
      "b    b\n",
      "c    c\n",
      "e    e\n",
      "g    g\n",
      "n    n\n",
      "o    o\n",
      "p    p\n",
      "w    w\n",
      "y    y\n",
      "Name: stalk-color-above-ring, dtype: object], [stalk-color-below-ring\n",
      "b    b\n",
      "c    c\n",
      "e    e\n",
      "g    g\n",
      "n    n\n",
      "o    o\n",
      "p    p\n",
      "w    w\n",
      "y    y\n",
      "Name: stalk-color-below-ring, dtype: object], [veil-color\n",
      "n    n\n",
      "o    o\n",
      "w    w\n",
      "y    y\n",
      "Name: veil-color, dtype: object], [ring-number\n",
      "n    n\n",
      "o    o\n",
      "t    t\n",
      "Name: ring-number, dtype: object], [ring-type\n",
      "e    e\n",
      "f    f\n",
      "l    l\n",
      "n    n\n",
      "p    p\n",
      "Name: ring-type, dtype: object], [spore-print-color\n",
      "b    b\n",
      "h    h\n",
      "k    k\n",
      "n    n\n",
      "o    o\n",
      "r    r\n",
      "u    u\n",
      "w    w\n",
      "y    y\n",
      "Name: spore-print-color, dtype: object], [population\n",
      "a    a\n",
      "c    c\n",
      "n    n\n",
      "s    s\n",
      "v    v\n",
      "y    y\n",
      "Name: population, dtype: object], [habitat\n",
      "d    d\n",
      "g    g\n",
      "l    l\n",
      "m    m\n",
      "p    p\n",
      "u    u\n",
      "w    w\n",
      "Name: habitat, dtype: object]]\n"
     ]
    }
   ],
   "source": [
    "# group of df\n",
    "col_list=[]\n",
    "cols=df.columns\n",
    "print(cols)\n",
    "for x in cols:\n",
    "    x=df[x].groupby(df[x]).first()\n",
    "    x=[x]\n",
    "    col_list.append(x)\n",
    "    \n",
    "print(col_list)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stalk-root\n",
       "b    3776\n",
       "c     556\n",
       "e    1120\n",
       "r     192\n",
       "Name: stalk-root, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['stalk-root'].isna().sum()\n",
    "df['stalk-root'].groupby(df['stalk-root']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['stalk-root']=df['stalk-root'].fillna('aa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      class  cap-shape  cap-surface  cap-color  bruises  odor  \\\n",
      "0         1          5            2          4        1     6   \n",
      "1         0          5            2          9        1     0   \n",
      "2         0          0            2          8        1     3   \n",
      "3         1          5            3          8        1     6   \n",
      "4         0          5            2          3        0     5   \n",
      "...     ...        ...          ...        ...      ...   ...   \n",
      "8119      0          3            2          4        0     5   \n",
      "8120      0          5            2          4        0     5   \n",
      "8121      0          2            2          4        0     5   \n",
      "8122      1          3            3          4        0     8   \n",
      "8123      0          5            2          4        0     5   \n",
      "\n",
      "      gill-attachment  gill-spacing  gill-size  gill-color  stalk-shape  \\\n",
      "0                   1             0          1           4            0   \n",
      "1                   1             0          0           4            0   \n",
      "2                   1             0          0           5            0   \n",
      "3                   1             0          1           5            0   \n",
      "4                   1             1          0           4            1   \n",
      "...               ...           ...        ...         ...          ...   \n",
      "8119                0             0          0          11            0   \n",
      "8120                0             0          0          11            0   \n",
      "8121                0             0          0           5            0   \n",
      "8122                1             0          1           0            1   \n",
      "8123                0             0          0          11            0   \n",
      "\n",
      "      stalk-root  stalk-surface-above-ring  stalk-surface-below-ring  \\\n",
      "0              3                         2                         2   \n",
      "1              2                         2                         2   \n",
      "2              2                         2                         2   \n",
      "3              3                         2                         2   \n",
      "4              3                         2                         2   \n",
      "...          ...                       ...                       ...   \n",
      "8119           0                         2                         2   \n",
      "8120           0                         2                         2   \n",
      "8121           0                         2                         2   \n",
      "8122           0                         2                         1   \n",
      "8123           0                         2                         2   \n",
      "\n",
      "      stalk-color-above-ring  stalk-color-below-ring  veil-color  ring-number  \\\n",
      "0                          7                       7           2            1   \n",
      "1                          7                       7           2            1   \n",
      "2                          7                       7           2            1   \n",
      "3                          7                       7           2            1   \n",
      "4                          7                       7           2            1   \n",
      "...                      ...                     ...         ...          ...   \n",
      "8119                       5                       5           1            1   \n",
      "8120                       5                       5           0            1   \n",
      "8121                       5                       5           1            1   \n",
      "8122                       7                       7           2            1   \n",
      "8123                       5                       5           1            1   \n",
      "\n",
      "      ring-type  spore-print-color  population  habitat  \n",
      "0             4                  2           3        5  \n",
      "1             4                  3           2        1  \n",
      "2             4                  3           2        3  \n",
      "3             4                  2           3        5  \n",
      "4             0                  3           0        1  \n",
      "...         ...                ...         ...      ...  \n",
      "8119          4                  0           1        2  \n",
      "8120          4                  0           4        2  \n",
      "8121          4                  0           1        2  \n",
      "8122          0                  7           4        2  \n",
      "8123          4                  4           1        2  \n",
      "\n",
      "[8124 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n",
    "for col in cols:\n",
    "    df[col]=le.fit_transform(df[col])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x253d226bac8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "dark"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "ax=sns.distplot(df['cap-shape'])\n",
    "#sns.distplot(df['class'])\n",
    "sns.distplot(df['gill-color'])\n",
    "#fig,a=plt.subplots(2,2)\n",
    "#a[0][0].plot(df['class'])\n",
    "#a[0][1].plot(df['cap-shape'])\n",
    "#a[1][0].plot(df['gill-color'])\n",
    "#a[1][1].plot(df['gill-size'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[class\n",
      "0       0\n",
      "1    3916\n",
      "Name: class, dtype: int32], [cap-shape\n",
      "0        0\n",
      "1        4\n",
      "2     6304\n",
      "3     2484\n",
      "4      128\n",
      "5    18280\n",
      "Name: cap-shape, dtype: int32], [cap-surface\n",
      "0       0\n",
      "1       4\n",
      "2    5112\n",
      "3    9732\n",
      "Name: cap-surface, dtype: int32], [cap-color\n",
      "0       0\n",
      "1      44\n",
      "2    3000\n",
      "3    5520\n",
      "4    9136\n",
      "5     720\n",
      "6      96\n",
      "7     112\n",
      "8    8320\n",
      "9    9648\n",
      "Name: cap-color, dtype: int32], [bruises\n",
      "0       0\n",
      "1    3376\n",
      "Name: bruises, dtype: int32], [odor\n",
      "0        0\n",
      "1      192\n",
      "2     4320\n",
      "3     1200\n",
      "4      144\n",
      "5    17640\n",
      "6     1536\n",
      "7     4032\n",
      "8     4608\n",
      "Name: odor, dtype: int32], [gill-attachment\n",
      "0       0\n",
      "1    7914\n",
      "Name: gill-attachment, dtype: int32], [gill-spacing\n",
      "0       0\n",
      "1    1312\n",
      "Name: gill-spacing, dtype: int32], [gill-size\n",
      "0       0\n",
      "1    2512\n",
      "Name: gill-size, dtype: int32], [gill-color\n",
      "0         0\n",
      "1        96\n",
      "2      1504\n",
      "3      2196\n",
      "4      1632\n",
      "5      5240\n",
      "6       384\n",
      "7     10444\n",
      "8       192\n",
      "9      4428\n",
      "10    12020\n",
      "11      946\n",
      "Name: gill-color, dtype: int32], [stalk-shape\n",
      "0       0\n",
      "1    4608\n",
      "Name: stalk-shape, dtype: int32], [stalk-root\n",
      "0       0\n",
      "1    3776\n",
      "2    1112\n",
      "3    3360\n",
      "4     768\n",
      "Name: stalk-root, dtype: int32], [stalk-surface-above-ring\n",
      "0        0\n",
      "1     2372\n",
      "2    10352\n",
      "3       72\n",
      "Name: stalk-surface-above-ring, dtype: int32], [stalk-surface-below-ring\n",
      "0       0\n",
      "1    2304\n",
      "2    9872\n",
      "3     852\n",
      "Name: stalk-surface-below-ring, dtype: int32], [stalk-color-above-ring\n",
      "0        0\n",
      "1       36\n",
      "2      192\n",
      "3     1728\n",
      "4     1792\n",
      "5      960\n",
      "6    11232\n",
      "7    31248\n",
      "8       64\n",
      "Name: stalk-color-above-ring, dtype: int32], [stalk-color-below-ring\n",
      "0        0\n",
      "1       36\n",
      "2      192\n",
      "3     1728\n",
      "4     2048\n",
      "5      960\n",
      "6    11232\n",
      "7    30688\n",
      "8      192\n",
      "Name: stalk-color-below-ring, dtype: int32], [veil-color\n",
      "0        0\n",
      "1       96\n",
      "2    15848\n",
      "3       24\n",
      "Name: veil-color, dtype: int32], [ring-number\n",
      "0       0\n",
      "1    7488\n",
      "2    1200\n",
      "Name: ring-number, dtype: int32], [ring-type\n",
      "0        0\n",
      "1       48\n",
      "2     2592\n",
      "3      108\n",
      "4    15872\n",
      "Name: ring-type, dtype: int32], [spore-print-color\n",
      "0        0\n",
      "1     1632\n",
      "2     3744\n",
      "3     5904\n",
      "4      192\n",
      "5      360\n",
      "6      288\n",
      "7    16716\n",
      "8      384\n",
      "Name: spore-print-color, dtype: int32], [population\n",
      "0        0\n",
      "1      340\n",
      "2      800\n",
      "3     3744\n",
      "4    16160\n",
      "5     8560\n",
      "Name: population, dtype: int32], [habitat\n",
      "0       0\n",
      "1    2148\n",
      "2    1664\n",
      "3     876\n",
      "4    4576\n",
      "5    1840\n",
      "6    1152\n",
      "Name: habitat, dtype: int32]]\n"
     ]
    }
   ],
   "source": [
    "group=[]\n",
    "for col in cols:\n",
    "    col=df[col].groupby(df[col]).sum()\n",
    "    col=[col]\n",
    "    group.append(col)\n",
    "print(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>cap-color</th>\n",
       "      <th>bruises</th>\n",
       "      <th>odor</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-size</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>stalk-shape</th>\n",
       "      <th>stalk-root</th>\n",
       "      <th>stalk-surface-above-ring</th>\n",
       "      <th>stalk-surface-below-ring</th>\n",
       "      <th>stalk-color-above-ring</th>\n",
       "      <th>stalk-color-below-ring</th>\n",
       "      <th>veil-color</th>\n",
       "      <th>ring-number</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>spore-print-color</th>\n",
       "      <th>population</th>\n",
       "      <th>habitat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8119</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8120</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8121</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8122</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8123</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8124 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      class  cap-shape  cap-surface  cap-color  bruises  odor  \\\n",
       "0         1          5            2          4        1     6   \n",
       "1         0          5            2          9        1     0   \n",
       "2         0          0            2          8        1     3   \n",
       "3         1          5            3          8        1     6   \n",
       "4         0          5            2          3        0     5   \n",
       "...     ...        ...          ...        ...      ...   ...   \n",
       "8119      0          3            2          4        0     5   \n",
       "8120      0          5            2          4        0     5   \n",
       "8121      0          2            2          4        0     5   \n",
       "8122      1          3            3          4        0     8   \n",
       "8123      0          5            2          4        0     5   \n",
       "\n",
       "      gill-attachment  gill-spacing  gill-size  gill-color  stalk-shape  \\\n",
       "0                   1             0          1           4            0   \n",
       "1                   1             0          0           4            0   \n",
       "2                   1             0          0           5            0   \n",
       "3                   1             0          1           5            0   \n",
       "4                   1             1          0           4            1   \n",
       "...               ...           ...        ...         ...          ...   \n",
       "8119                0             0          0          11            0   \n",
       "8120                0             0          0          11            0   \n",
       "8121                0             0          0           5            0   \n",
       "8122                1             0          1           0            1   \n",
       "8123                0             0          0          11            0   \n",
       "\n",
       "      stalk-root  stalk-surface-above-ring  stalk-surface-below-ring  \\\n",
       "0              3                         2                         2   \n",
       "1              2                         2                         2   \n",
       "2              2                         2                         2   \n",
       "3              3                         2                         2   \n",
       "4              3                         2                         2   \n",
       "...          ...                       ...                       ...   \n",
       "8119           0                         2                         2   \n",
       "8120           0                         2                         2   \n",
       "8121           0                         2                         2   \n",
       "8122           0                         2                         1   \n",
       "8123           0                         2                         2   \n",
       "\n",
       "      stalk-color-above-ring  stalk-color-below-ring  veil-color  ring-number  \\\n",
       "0                          7                       7           2            1   \n",
       "1                          7                       7           2            1   \n",
       "2                          7                       7           2            1   \n",
       "3                          7                       7           2            1   \n",
       "4                          7                       7           2            1   \n",
       "...                      ...                     ...         ...          ...   \n",
       "8119                       5                       5           1            1   \n",
       "8120                       5                       5           0            1   \n",
       "8121                       5                       5           1            1   \n",
       "8122                       7                       7           2            1   \n",
       "8123                       5                       5           1            1   \n",
       "\n",
       "      ring-type  spore-print-color  population  habitat  \n",
       "0             4                  2           3        5  \n",
       "1             4                  3           2        1  \n",
       "2             4                  3           2        3  \n",
       "3             4                  2           3        5  \n",
       "4             0                  3           0        1  \n",
       "...         ...                ...         ...      ...  \n",
       "8119          4                  0           1        2  \n",
       "8120          4                  0           4        2  \n",
       "8121          4                  0           1        2  \n",
       "8122          0                  7           4        2  \n",
       "8123          4                  4           1        2  \n",
       "\n",
       "[8124 rows x 22 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spliting data\n",
    "x=df.drop(columns='class')\n",
    "y=df['class']\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_tain,X_test,Y_train,Y_test=train_test_split(x,y,test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SMOTE scaling for imbalanced data handling\n",
    "def makeOverSamplesSMOTE(x,y):\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    sm=SMOTE()\n",
    "    x,y=sm.fit_sample(x,y)\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(      cap-shape  cap-surface  cap-color  bruises  odor  gill-attachment  \\\n",
       " 0             5            2          4        1     6                1   \n",
       " 1             5            2          9        1     0                1   \n",
       " 2             0            2          8        1     3                1   \n",
       " 3             5            3          8        1     6                1   \n",
       " 4             5            2          3        0     5                1   \n",
       " ...         ...          ...        ...      ...   ...              ...   \n",
       " 8411          3            2          2        0     2                1   \n",
       " 8412          2            3          4        0     2                1   \n",
       " 8413          2            3          4        0     8                1   \n",
       " 8414          2            3          3        0     2                1   \n",
       " 8415          2            3          3        0     2                1   \n",
       " \n",
       "       gill-spacing  gill-size  gill-color  stalk-shape  stalk-root  \\\n",
       " 0                0          1           4            0           3   \n",
       " 1                0          0           4            0           2   \n",
       " 2                0          0           5            0           2   \n",
       " 3                0          1           5            0           3   \n",
       " 4                1          0           4            1           3   \n",
       " ...            ...        ...         ...          ...         ...   \n",
       " 8411             0          1           0            1           0   \n",
       " 8412             0          1           0            1           0   \n",
       " 8413             0          1           0            1           0   \n",
       " 8414             0          0           2            0           1   \n",
       " 8415             0          0           7            0           1   \n",
       " \n",
       "       stalk-surface-above-ring  stalk-surface-below-ring  \\\n",
       " 0                            2                         2   \n",
       " 1                            2                         2   \n",
       " 2                            2                         2   \n",
       " 3                            2                         2   \n",
       " 4                            2                         2   \n",
       " ...                        ...                       ...   \n",
       " 8411                         1                         1   \n",
       " 8412                         2                         1   \n",
       " 8413                         1                         2   \n",
       " 8414                         1                         1   \n",
       " 8415                         1                         1   \n",
       " \n",
       "       stalk-color-above-ring  stalk-color-below-ring  veil-color  ring-number  \\\n",
       " 0                          7                       7           2            1   \n",
       " 1                          7                       7           2            1   \n",
       " 2                          7                       7           2            1   \n",
       " 3                          7                       7           2            1   \n",
       " 4                          7                       7           2            1   \n",
       " ...                      ...                     ...         ...          ...   \n",
       " 8411                       7                       6           2            1   \n",
       " 8412                       7                       6           2            1   \n",
       " 8413                       6                       6           2            1   \n",
       " 8414                       5                       6           2            1   \n",
       " 8415                       0                       6           2            1   \n",
       " \n",
       "       ring-type  spore-print-color  population  habitat  \n",
       " 0             4                  2           3        5  \n",
       " 1             4                  3           2        1  \n",
       " 2             4                  3           2        3  \n",
       " 3             4                  2           3        5  \n",
       " 4             0                  3           0        1  \n",
       " ...         ...                ...         ...      ...  \n",
       " 8411          0                  7           4        0  \n",
       " 8412          0                  7           4        0  \n",
       " 8413          0                  7           4        4  \n",
       " 8414          2                  1           4        4  \n",
       " 8415          2                  1           4        1  \n",
       " \n",
       " [8416 rows x 21 columns], 0       1\n",
       " 1       0\n",
       " 2       0\n",
       " 3       1\n",
       " 4       0\n",
       "        ..\n",
       " 8411    1\n",
       " 8412    1\n",
       " 8413    1\n",
       " 8414    1\n",
       " 8415    1\n",
       " Name: class, Length: 8416, dtype: int32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "makeOverSamplesSMOTE(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling using ADASYN\n",
    "def makeOverSamplesADASYN(x,y):\n",
    "    from imblearn.over_sampling import ADASYN\n",
    "    sm=ADASYN()\n",
    "    x,y=sm.fit_sample(x,y)\n",
    "    return x,y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(      cap-shape  cap-surface  cap-color  bruises  odor  gill-attachment  \\\n",
       " 0             5            2          4        1     6                1   \n",
       " 1             5            2          9        1     0                1   \n",
       " 2             0            2          8        1     3                1   \n",
       " 3             5            3          8        1     6                1   \n",
       " 4             5            2          3        0     5                1   \n",
       " ...         ...          ...        ...      ...   ...              ...   \n",
       " 8413          0            1          4        0     5                1   \n",
       " 8414          1            2          4        0     5                1   \n",
       " 8415          0            0          4        0     5                1   \n",
       " 8416          0            0          4        0     5                1   \n",
       " 8417          0            0          4        0     5                1   \n",
       " \n",
       "       gill-spacing  gill-size  gill-color  stalk-shape  stalk-root  \\\n",
       " 0                0          1           4            0           3   \n",
       " 1                0          0           4            0           2   \n",
       " 2                0          0           5            0           2   \n",
       " 3                0          1           5            0           3   \n",
       " 4                1          0           4            1           3   \n",
       " ...            ...        ...         ...          ...         ...   \n",
       " 8413             0          1          10            0           0   \n",
       " 8414             0          1          10            0           0   \n",
       " 8415             0          1          10            0           0   \n",
       " 8416             0          1          10            0           0   \n",
       " 8417             0          1          10            0           0   \n",
       " \n",
       "       stalk-surface-above-ring  stalk-surface-below-ring  \\\n",
       " 0                            2                         2   \n",
       " 1                            2                         2   \n",
       " 2                            2                         2   \n",
       " 3                            2                         2   \n",
       " 4                            2                         2   \n",
       " ...                        ...                       ...   \n",
       " 8413                         1                         3   \n",
       " 8414                         1                         3   \n",
       " 8415                         1                         3   \n",
       " 8416                         1                         3   \n",
       " 8417                         1                         3   \n",
       " \n",
       "       stalk-color-above-ring  stalk-color-below-ring  veil-color  ring-number  \\\n",
       " 0                          7                       7           2            1   \n",
       " 1                          7                       7           2            1   \n",
       " 2                          7                       7           2            1   \n",
       " 3                          7                       7           2            1   \n",
       " 4                          7                       7           2            1   \n",
       " ...                      ...                     ...         ...          ...   \n",
       " 8413                       7                       4           2            1   \n",
       " 8414                       7                       4           2            1   \n",
       " 8415                       7                       4           2            1   \n",
       " 8416                       7                       4           2            1   \n",
       " 8417                       7                       4           2            1   \n",
       " \n",
       "       ring-type  spore-print-color  population  habitat  \n",
       " 0             4                  2           3        5  \n",
       " 1             4                  3           2        1  \n",
       " 2             4                  3           2        3  \n",
       " 3             4                  2           3        5  \n",
       " 4             0                  3           0        1  \n",
       " ...         ...                ...         ...      ...  \n",
       " 8413          0                  7           4        0  \n",
       " 8414          0                  7           4        0  \n",
       " 8415          0                  7           4        0  \n",
       " 8416          0                  7           4        0  \n",
       " 8417          0                  7           4        0  \n",
       " \n",
       " [8418 rows x 21 columns], 0       1\n",
       " 1       0\n",
       " 2       0\n",
       " 3       1\n",
       " 4       0\n",
       "        ..\n",
       " 8413    1\n",
       " 8414    1\n",
       " 8415    1\n",
       " 8416    1\n",
       " 8417    1\n",
       " Name: class, Length: 8418, dtype: int32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "makeOverSamplesADASYN(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the data\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.25,random_state=0)\n",
    "from sklearn import preprocessing\n",
    "x_scaled=preprocessing.scale(xtrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for i:  1\n",
      "Accuracy score:  0.947316592811423\n",
      "Confusion matrix:\n",
      " [[1019   42]\n",
      " [  65  905]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95      1061\n",
      "           1       0.96      0.93      0.94       970\n",
      "\n",
      "    accuracy                           0.95      2031\n",
      "   macro avg       0.95      0.95      0.95      2031\n",
      "weighted avg       0.95      0.95      0.95      2031\n",
      "\n",
      "for i:  2\n",
      "Accuracy score:  0.947316592811423\n",
      "Confusion matrix:\n",
      " [[1019   42]\n",
      " [  65  905]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95      1061\n",
      "           1       0.96      0.93      0.94       970\n",
      "\n",
      "    accuracy                           0.95      2031\n",
      "   macro avg       0.95      0.95      0.95      2031\n",
      "weighted avg       0.95      0.95      0.95      2031\n",
      "\n",
      "for i:  3\n",
      "Accuracy score:  0.947316592811423\n",
      "Confusion matrix:\n",
      " [[1019   42]\n",
      " [  65  905]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95      1061\n",
      "           1       0.96      0.93      0.94       970\n",
      "\n",
      "    accuracy                           0.95      2031\n",
      "   macro avg       0.95      0.95      0.95      2031\n",
      "weighted avg       0.95      0.95      0.95      2031\n",
      "\n",
      "for i:  4\n",
      "Accuracy score:  0.947316592811423\n",
      "Confusion matrix:\n",
      " [[1019   42]\n",
      " [  65  905]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95      1061\n",
      "           1       0.96      0.93      0.94       970\n",
      "\n",
      "    accuracy                           0.95      2031\n",
      "   macro avg       0.95      0.95      0.95      2031\n",
      "weighted avg       0.95      0.95      0.95      2031\n",
      "\n",
      "for i:  5\n",
      "Accuracy score:  0.947316592811423\n",
      "Confusion matrix:\n",
      " [[1019   42]\n",
      " [  65  905]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95      1061\n",
      "           1       0.96      0.93      0.94       970\n",
      "\n",
      "    accuracy                           0.95      2031\n",
      "   macro avg       0.95      0.95      0.95      2031\n",
      "weighted avg       0.95      0.95      0.95      2031\n",
      "\n",
      "for i:  6\n",
      "Accuracy score:  0.947316592811423\n",
      "Confusion matrix:\n",
      " [[1019   42]\n",
      " [  65  905]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95      1061\n",
      "           1       0.96      0.93      0.94       970\n",
      "\n",
      "    accuracy                           0.95      2031\n",
      "   macro avg       0.95      0.95      0.95      2031\n",
      "weighted avg       0.95      0.95      0.95      2031\n",
      "\n",
      "for i:  7\n",
      "Accuracy score:  0.947316592811423\n",
      "Confusion matrix:\n",
      " [[1019   42]\n",
      " [  65  905]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95      1061\n",
      "           1       0.96      0.93      0.94       970\n",
      "\n",
      "    accuracy                           0.95      2031\n",
      "   macro avg       0.95      0.95      0.95      2031\n",
      "weighted avg       0.95      0.95      0.95      2031\n",
      "\n",
      "for i:  8\n",
      "Accuracy score:  0.947316592811423\n",
      "Confusion matrix:\n",
      " [[1019   42]\n",
      " [  65  905]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95      1061\n",
      "           1       0.96      0.93      0.94       970\n",
      "\n",
      "    accuracy                           0.95      2031\n",
      "   macro avg       0.95      0.95      0.95      2031\n",
      "weighted avg       0.95      0.95      0.95      2031\n",
      "\n",
      "for i:  9\n",
      "Accuracy score:  0.947316592811423\n",
      "Confusion matrix:\n",
      " [[1019   42]\n",
      " [  65  905]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95      1061\n",
      "           1       0.96      0.93      0.94       970\n",
      "\n",
      "    accuracy                           0.95      2031\n",
      "   macro avg       0.95      0.95      0.95      2031\n",
      "weighted avg       0.95      0.95      0.95      2031\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
    "ac=[]\n",
    "for i in range(1,10):\n",
    "    print(\"for i: \",i)\n",
    "    lr=LogisticRegression(random_state=i,max_iter=500)\n",
    "    lr.fit(xtrain,ytrain)\n",
    "    lr_pred=lr.predict(xtest)\n",
    "    lr_acc=accuracy_score(lr_pred,ytest)\n",
    "    ac.append(lr_acc)\n",
    "    print(\"Accuracy score: \",lr_acc)\n",
    "    lr_cm=confusion_matrix(ytest,lr_pred)\n",
    "    print(\"Confusion matrix:\\n\",lr_cm)\n",
    "    lr_cr=classification_report(ytest,lr_pred)\n",
    "    print(\"Classification report:\\n\",lr_cr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.947316592811423\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy score: \",max(ac))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for train:  0.22519754444187207\n",
      "RMSE for test:  0.22952866310893952\n",
      "R^2 score:  0.7888424652875619\n",
      "Accuracy:  0.947316592811423\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "lr=LogisticRegression(random_state=1,max_iter=500)\n",
    "lr.fit(xtrain,ytrain)\n",
    "lr_pred=lr.predict(xtest)\n",
    "#RMSE for training\n",
    "lr_pred_train=lr.predict(xtrain)\n",
    "lr_rmse_train=np.sqrt(mean_squared_error(ytrain,lr_pred_train))\n",
    "print(\"RMSE for train: \",lr_rmse_train)\n",
    "#RMSE for test\n",
    "lr_pred_test=lr.predict(xtest)\n",
    "lr_rmse_test=np.sqrt(mean_squared_error(ytest,lr_pred_test))\n",
    "print(\"RMSE for test: \",lr_rmse_test)\n",
    "print(\"R^2 score: \",r2_score(ytest,lr_pred))\n",
    "lr_acc1=accuracy_score(lr_pred,ytest)\n",
    "print(\"Accuracy: \",lr_acc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 1\n",
      "Accuracy score:  0.5224027572624323\n",
      "Confusion matrix:\n",
      " [[1061    0]\n",
      " [ 970    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MaheshHiremath\\Anaconda3-2019.10\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\MaheshHiremath\\Anaconda3-2019.10\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\MaheshHiremath\\Anaconda3-2019.10\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      1.00      0.69      1061\n",
      "           1       0.00      0.00      0.00       970\n",
      "\n",
      "    accuracy                           0.52      2031\n",
      "   macro avg       0.26      0.50      0.34      2031\n",
      "weighted avg       0.27      0.52      0.36      2031\n",
      "\n",
      "i= 2\n",
      "Accuracy score:  0.5224027572624323\n",
      "Confusion matrix:\n",
      " [[1061    0]\n",
      " [ 970    0]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      1.00      0.69      1061\n",
      "           1       0.00      0.00      0.00       970\n",
      "\n",
      "    accuracy                           0.52      2031\n",
      "   macro avg       0.26      0.50      0.34      2031\n",
      "weighted avg       0.27      0.52      0.36      2031\n",
      "\n",
      "i= 3\n",
      "Accuracy score:  0.5224027572624323\n",
      "Confusion matrix:\n",
      " [[1061    0]\n",
      " [ 970    0]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      1.00      0.69      1061\n",
      "           1       0.00      0.00      0.00       970\n",
      "\n",
      "    accuracy                           0.52      2031\n",
      "   macro avg       0.26      0.50      0.34      2031\n",
      "weighted avg       0.27      0.52      0.36      2031\n",
      "\n",
      "i= 4\n",
      "Accuracy score:  0.5224027572624323\n",
      "Confusion matrix:\n",
      " [[1061    0]\n",
      " [ 970    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MaheshHiremath\\Anaconda3-2019.10\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\MaheshHiremath\\Anaconda3-2019.10\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\MaheshHiremath\\Anaconda3-2019.10\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      1.00      0.69      1061\n",
      "           1       0.00      0.00      0.00       970\n",
      "\n",
      "    accuracy                           0.52      2031\n",
      "   macro avg       0.26      0.50      0.34      2031\n",
      "weighted avg       0.27      0.52      0.36      2031\n",
      "\n",
      "i= 5\n",
      "Accuracy score:  0.5224027572624323\n",
      "Confusion matrix:\n",
      " [[1061    0]\n",
      " [ 970    0]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      1.00      0.69      1061\n",
      "           1       0.00      0.00      0.00       970\n",
      "\n",
      "    accuracy                           0.52      2031\n",
      "   macro avg       0.26      0.50      0.34      2031\n",
      "weighted avg       0.27      0.52      0.36      2031\n",
      "\n",
      "i= 6\n",
      "Accuracy score:  0.5224027572624323\n",
      "Confusion matrix:\n",
      " [[1061    0]\n",
      " [ 970    0]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      1.00      0.69      1061\n",
      "           1       0.00      0.00      0.00       970\n",
      "\n",
      "    accuracy                           0.52      2031\n",
      "   macro avg       0.26      0.50      0.34      2031\n",
      "weighted avg       0.27      0.52      0.36      2031\n",
      "\n",
      "i= 7\n",
      "Accuracy score:  0.5224027572624323\n",
      "Confusion matrix:\n",
      " [[1061    0]\n",
      " [ 970    0]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      1.00      0.69      1061\n",
      "           1       0.00      0.00      0.00       970\n",
      "\n",
      "    accuracy                           0.52      2031\n",
      "   macro avg       0.26      0.50      0.34      2031\n",
      "weighted avg       0.27      0.52      0.36      2031\n",
      "\n",
      "i= 8\n",
      "Accuracy score:  0.5224027572624323\n",
      "Confusion matrix:\n",
      " [[1061    0]\n",
      " [ 970    0]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      1.00      0.69      1061\n",
      "           1       0.00      0.00      0.00       970\n",
      "\n",
      "    accuracy                           0.52      2031\n",
      "   macro avg       0.26      0.50      0.34      2031\n",
      "weighted avg       0.27      0.52      0.36      2031\n",
      "\n",
      "i= 9\n",
      "Accuracy score:  0.5224027572624323\n",
      "Confusion matrix:\n",
      " [[1061    0]\n",
      " [ 970    0]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      1.00      0.69      1061\n",
      "           1       0.00      0.00      0.00       970\n",
      "\n",
      "    accuracy                           0.52      2031\n",
      "   macro avg       0.26      0.50      0.34      2031\n",
      "weighted avg       0.27      0.52      0.36      2031\n",
      "\n",
      "i= 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MaheshHiremath\\Anaconda3-2019.10\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\MaheshHiremath\\Anaconda3-2019.10\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\MaheshHiremath\\Anaconda3-2019.10\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.5224027572624323\n",
      "Confusion matrix:\n",
      " [[1061    0]\n",
      " [ 970    0]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      1.00      0.69      1061\n",
      "           1       0.00      0.00      0.00       970\n",
      "\n",
      "    accuracy                           0.52      2031\n",
      "   macro avg       0.26      0.50      0.34      2031\n",
      "weighted avg       0.27      0.52      0.36      2031\n",
      "\n",
      "i= 11\n",
      "Accuracy score:  0.5224027572624323\n",
      "Confusion matrix:\n",
      " [[1061    0]\n",
      " [ 970    0]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      1.00      0.69      1061\n",
      "           1       0.00      0.00      0.00       970\n",
      "\n",
      "    accuracy                           0.52      2031\n",
      "   macro avg       0.26      0.50      0.34      2031\n",
      "weighted avg       0.27      0.52      0.36      2031\n",
      "\n",
      "i= 12\n",
      "Accuracy score:  0.5224027572624323\n",
      "Confusion matrix:\n",
      " [[1061    0]\n",
      " [ 970    0]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      1.00      0.69      1061\n",
      "           1       0.00      0.00      0.00       970\n",
      "\n",
      "    accuracy                           0.52      2031\n",
      "   macro avg       0.26      0.50      0.34      2031\n",
      "weighted avg       0.27      0.52      0.36      2031\n",
      "\n",
      "i= 13\n",
      "Accuracy score: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MaheshHiremath\\Anaconda3-2019.10\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\MaheshHiremath\\Anaconda3-2019.10\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\MaheshHiremath\\Anaconda3-2019.10\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.5224027572624323\n",
      "Confusion matrix:\n",
      " [[1061    0]\n",
      " [ 970    0]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      1.00      0.69      1061\n",
      "           1       0.00      0.00      0.00       970\n",
      "\n",
      "    accuracy                           0.52      2031\n",
      "   macro avg       0.26      0.50      0.34      2031\n",
      "weighted avg       0.27      0.52      0.36      2031\n",
      "\n",
      "i= 14\n",
      "Accuracy score:  0.5224027572624323\n",
      "Confusion matrix:\n",
      " [[1061    0]\n",
      " [ 970    0]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      1.00      0.69      1061\n",
      "           1       0.00      0.00      0.00       970\n",
      "\n",
      "    accuracy                           0.52      2031\n",
      "   macro avg       0.26      0.50      0.34      2031\n",
      "weighted avg       0.27      0.52      0.36      2031\n",
      "\n",
      "i= 15\n",
      "Accuracy score:  0.5224027572624323\n",
      "Confusion matrix:\n",
      " [[1061    0]\n",
      " [ 970    0]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      1.00      0.69      1061\n",
      "           1       0.00      0.00      0.00       970\n",
      "\n",
      "    accuracy                           0.52      2031\n",
      "   macro avg       0.26      0.50      0.34      2031\n",
      "weighted avg       0.27      0.52      0.36      2031\n",
      "\n",
      "i= 16\n",
      "Accuracy score: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MaheshHiremath\\Anaconda3-2019.10\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\MaheshHiremath\\Anaconda3-2019.10\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\MaheshHiremath\\Anaconda3-2019.10\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.5224027572624323\n",
      "Confusion matrix:\n",
      " [[1061    0]\n",
      " [ 970    0]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      1.00      0.69      1061\n",
      "           1       0.00      0.00      0.00       970\n",
      "\n",
      "    accuracy                           0.52      2031\n",
      "   macro avg       0.26      0.50      0.34      2031\n",
      "weighted avg       0.27      0.52      0.36      2031\n",
      "\n",
      "i= 17\n",
      "Accuracy score:  0.5224027572624323\n",
      "Confusion matrix:\n",
      " [[1061    0]\n",
      " [ 970    0]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      1.00      0.69      1061\n",
      "           1       0.00      0.00      0.00       970\n",
      "\n",
      "    accuracy                           0.52      2031\n",
      "   macro avg       0.26      0.50      0.34      2031\n",
      "weighted avg       0.27      0.52      0.36      2031\n",
      "\n",
      "i= 18\n",
      "Accuracy score:  0.5224027572624323\n",
      "Confusion matrix:\n",
      " [[1061    0]\n",
      " [ 970    0]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      1.00      0.69      1061\n",
      "           1       0.00      0.00      0.00       970\n",
      "\n",
      "    accuracy                           0.52      2031\n",
      "   macro avg       0.26      0.50      0.34      2031\n",
      "weighted avg       0.27      0.52      0.36      2031\n",
      "\n",
      "i= 19\n",
      "Accuracy score: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MaheshHiremath\\Anaconda3-2019.10\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\MaheshHiremath\\Anaconda3-2019.10\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\MaheshHiremath\\Anaconda3-2019.10\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\MaheshHiremath\\Anaconda3-2019.10\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.5224027572624323\n",
      "Confusion matrix:\n",
      " [[1061    0]\n",
      " [ 970    0]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      1.00      0.69      1061\n",
      "           1       0.00      0.00      0.00       970\n",
      "\n",
      "    accuracy                           0.52      2031\n",
      "   macro avg       0.26      0.50      0.34      2031\n",
      "weighted avg       0.27      0.52      0.36      2031\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "acc=[]\n",
    "for i in range(1,20):\n",
    "    print(\"i=\",i)\n",
    "    dt=DecisionTreeClassifier(random_state=i)\n",
    "    dt.fit(x_scaled,ytrain)\n",
    "    dt_predt=dt.predict(xtest)\n",
    "    dt_acc=accuracy_score(dt_predt,ytest)\n",
    "    acc.append(dt_acc)\n",
    "    print(\"Accuracy score: \",dt_acc)\n",
    "    dt_cm=confusion_matrix(ytest,dt_predt)\n",
    "    print(\"Confusion matrix:\\n\",dt_cm)\n",
    "    dt_cr=classification_report(ytest,dt_predt)\n",
    "    print(\"Classification report:\\n\",dt_cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.5224027572624323\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy score: \",max(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as confusion matrix has TN and FN as 0 decision tree model is biased"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for i:  1\n",
      "Accuracy score:  1.0\n",
      "Confusion matrix:\n",
      " [[1061    0]\n",
      " [   0  970]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1061\n",
      "           1       1.00      1.00      1.00       970\n",
      "\n",
      "    accuracy                           1.00      2031\n",
      "   macro avg       1.00      1.00      1.00      2031\n",
      "weighted avg       1.00      1.00      1.00      2031\n",
      "\n",
      "for i:  2\n",
      "Accuracy score:  1.0\n",
      "Confusion matrix:\n",
      " [[1061    0]\n",
      " [   0  970]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1061\n",
      "           1       1.00      1.00      1.00       970\n",
      "\n",
      "    accuracy                           1.00      2031\n",
      "   macro avg       1.00      1.00      1.00      2031\n",
      "weighted avg       1.00      1.00      1.00      2031\n",
      "\n",
      "for i:  3\n",
      "Accuracy score:  1.0\n",
      "Confusion matrix:\n",
      " [[1061    0]\n",
      " [   0  970]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1061\n",
      "           1       1.00      1.00      1.00       970\n",
      "\n",
      "    accuracy                           1.00      2031\n",
      "   macro avg       1.00      1.00      1.00      2031\n",
      "weighted avg       1.00      1.00      1.00      2031\n",
      "\n",
      "for i:  4\n",
      "Accuracy score:  1.0\n",
      "Confusion matrix:\n",
      " [[1061    0]\n",
      " [   0  970]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1061\n",
      "           1       1.00      1.00      1.00       970\n",
      "\n",
      "    accuracy                           1.00      2031\n",
      "   macro avg       1.00      1.00      1.00      2031\n",
      "weighted avg       1.00      1.00      1.00      2031\n",
      "\n",
      "for i:  5\n",
      "Accuracy score:  1.0\n",
      "Confusion matrix:\n",
      " [[1061    0]\n",
      " [   0  970]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1061\n",
      "           1       1.00      1.00      1.00       970\n",
      "\n",
      "    accuracy                           1.00      2031\n",
      "   macro avg       1.00      1.00      1.00      2031\n",
      "weighted avg       1.00      1.00      1.00      2031\n",
      "\n",
      "for i:  6\n",
      "Accuracy score:  1.0\n",
      "Confusion matrix:\n",
      " [[1061    0]\n",
      " [   0  970]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1061\n",
      "           1       1.00      1.00      1.00       970\n",
      "\n",
      "    accuracy                           1.00      2031\n",
      "   macro avg       1.00      1.00      1.00      2031\n",
      "weighted avg       1.00      1.00      1.00      2031\n",
      "\n",
      "for i:  7\n",
      "Accuracy score:  1.0\n",
      "Confusion matrix:\n",
      " [[1061    0]\n",
      " [   0  970]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1061\n",
      "           1       1.00      1.00      1.00       970\n",
      "\n",
      "    accuracy                           1.00      2031\n",
      "   macro avg       1.00      1.00      1.00      2031\n",
      "weighted avg       1.00      1.00      1.00      2031\n",
      "\n",
      "for i:  8\n",
      "Accuracy score:  1.0\n",
      "Confusion matrix:\n",
      " [[1061    0]\n",
      " [   0  970]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1061\n",
      "           1       1.00      1.00      1.00       970\n",
      "\n",
      "    accuracy                           1.00      2031\n",
      "   macro avg       1.00      1.00      1.00      2031\n",
      "weighted avg       1.00      1.00      1.00      2031\n",
      "\n",
      "for i:  9\n",
      "Accuracy score:  1.0\n",
      "Confusion matrix:\n",
      " [[1061    0]\n",
      " [   0  970]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1061\n",
      "           1       1.00      1.00      1.00       970\n",
      "\n",
      "    accuracy                           1.00      2031\n",
      "   macro avg       1.00      1.00      1.00      2031\n",
      "weighted avg       1.00      1.00      1.00      2031\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "acc_r=[]\n",
    "for i in range(1,10):\n",
    "    print(\"for i: \",i)\n",
    "    ran=RandomForestClassifier(n_estimators=500,random_state=i)\n",
    "    ran.fit(xtrain,ytrain)\n",
    "    ran_predt=ran.predict(xtest)\n",
    "    ran_acc=accuracy_score(ran_predt,ytest)\n",
    "    acc_r.append(ran_acc)\n",
    "    print(\"Accuracy score: \",ran_acc)\n",
    "    ran_cm=confusion_matrix(ran_predt,ytest)\n",
    "    print(\"Confusion matrix:\\n\",ran_cm)\n",
    "    ran_cr=classification_report(ran_predt,ytest)\n",
    "    print('Classification report:\\n',ran_cr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for i:  1\n",
      "Accuracy score:  0.758739537173806\n",
      "Confusion matrix:\n",
      " [[1005  434]\n",
      " [  56  536]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.70      0.80      1439\n",
      "           1       0.55      0.91      0.69       592\n",
      "\n",
      "    accuracy                           0.76      2031\n",
      "   macro avg       0.75      0.80      0.75      2031\n",
      "weighted avg       0.83      0.76      0.77      2031\n",
      "\n",
      "for i:  2\n",
      "Accuracy score:  0.758739537173806\n",
      "Confusion matrix:\n",
      " [[1005  434]\n",
      " [  56  536]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.70      0.80      1439\n",
      "           1       0.55      0.91      0.69       592\n",
      "\n",
      "    accuracy                           0.76      2031\n",
      "   macro avg       0.75      0.80      0.75      2031\n",
      "weighted avg       0.83      0.76      0.77      2031\n",
      "\n",
      "for i:  3\n",
      "Accuracy score:  0.758739537173806\n",
      "Confusion matrix:\n",
      " [[1005  434]\n",
      " [  56  536]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.70      0.80      1439\n",
      "           1       0.55      0.91      0.69       592\n",
      "\n",
      "    accuracy                           0.76      2031\n",
      "   macro avg       0.75      0.80      0.75      2031\n",
      "weighted avg       0.83      0.76      0.77      2031\n",
      "\n",
      "for i:  4\n",
      "Accuracy score:  0.7641555883801083\n",
      "Confusion matrix:\n",
      " [[1005  423]\n",
      " [  56  547]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.70      0.81      1428\n",
      "           1       0.56      0.91      0.70       603\n",
      "\n",
      "    accuracy                           0.76      2031\n",
      "   macro avg       0.76      0.81      0.75      2031\n",
      "weighted avg       0.83      0.76      0.77      2031\n",
      "\n",
      "for i:  5\n",
      "Accuracy score:  0.758739537173806\n",
      "Confusion matrix:\n",
      " [[1005  434]\n",
      " [  56  536]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.70      0.80      1439\n",
      "           1       0.55      0.91      0.69       592\n",
      "\n",
      "    accuracy                           0.76      2031\n",
      "   macro avg       0.75      0.80      0.75      2031\n",
      "weighted avg       0.83      0.76      0.77      2031\n",
      "\n",
      "for i:  6\n",
      "Accuracy score:  0.758739537173806\n",
      "Confusion matrix:\n",
      " [[1005  434]\n",
      " [  56  536]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.70      0.80      1439\n",
      "           1       0.55      0.91      0.69       592\n",
      "\n",
      "    accuracy                           0.76      2031\n",
      "   macro avg       0.75      0.80      0.75      2031\n",
      "weighted avg       0.83      0.76      0.77      2031\n",
      "\n",
      "for i:  7\n",
      "Accuracy score:  0.758739537173806\n",
      "Confusion matrix:\n",
      " [[1005  434]\n",
      " [  56  536]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.70      0.80      1439\n",
      "           1       0.55      0.91      0.69       592\n",
      "\n",
      "    accuracy                           0.76      2031\n",
      "   macro avg       0.75      0.80      0.75      2031\n",
      "weighted avg       0.83      0.76      0.77      2031\n",
      "\n",
      "for i:  8\n",
      "Accuracy score:  0.758739537173806\n",
      "Confusion matrix:\n",
      " [[1005  434]\n",
      " [  56  536]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.70      0.80      1439\n",
      "           1       0.55      0.91      0.69       592\n",
      "\n",
      "    accuracy                           0.76      2031\n",
      "   macro avg       0.75      0.80      0.75      2031\n",
      "weighted avg       0.83      0.76      0.77      2031\n",
      "\n",
      "for i:  9\n",
      "Accuracy score:  0.758739537173806\n",
      "Confusion matrix:\n",
      " [[1005  434]\n",
      " [  56  536]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.70      0.80      1439\n",
      "           1       0.55      0.91      0.69       592\n",
      "\n",
      "    accuracy                           0.76      2031\n",
      "   macro avg       0.75      0.80      0.75      2031\n",
      "weighted avg       0.83      0.76      0.77      2031\n",
      "\n",
      "for i:  10\n",
      "Accuracy score:  0.758739537173806\n",
      "Confusion matrix:\n",
      " [[1005  434]\n",
      " [  56  536]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.70      0.80      1439\n",
      "           1       0.55      0.91      0.69       592\n",
      "\n",
      "    accuracy                           0.76      2031\n",
      "   macro avg       0.75      0.80      0.75      2031\n",
      "weighted avg       0.83      0.76      0.77      2031\n",
      "\n",
      "for i:  11\n",
      "Accuracy score:  0.758739537173806\n",
      "Confusion matrix:\n",
      " [[1005  434]\n",
      " [  56  536]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.70      0.80      1439\n",
      "           1       0.55      0.91      0.69       592\n",
      "\n",
      "    accuracy                           0.76      2031\n",
      "   macro avg       0.75      0.80      0.75      2031\n",
      "weighted avg       0.83      0.76      0.77      2031\n",
      "\n",
      "for i:  12\n",
      "Accuracy score:  0.758739537173806\n",
      "Confusion matrix:\n",
      " [[1005  434]\n",
      " [  56  536]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.70      0.80      1439\n",
      "           1       0.55      0.91      0.69       592\n",
      "\n",
      "    accuracy                           0.76      2031\n",
      "   macro avg       0.75      0.80      0.75      2031\n",
      "weighted avg       0.83      0.76      0.77      2031\n",
      "\n",
      "for i:  13\n",
      "Accuracy score:  0.758739537173806\n",
      "Confusion matrix:\n",
      " [[1005  434]\n",
      " [  56  536]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.70      0.80      1439\n",
      "           1       0.55      0.91      0.69       592\n",
      "\n",
      "    accuracy                           0.76      2031\n",
      "   macro avg       0.75      0.80      0.75      2031\n",
      "weighted avg       0.83      0.76      0.77      2031\n",
      "\n",
      "for i:  14\n",
      "Accuracy score:  0.7646479566715904\n",
      "Confusion matrix:\n",
      " [[1017  434]\n",
      " [  44  536]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.70      0.81      1451\n",
      "           1       0.55      0.92      0.69       580\n",
      "\n",
      "    accuracy                           0.76      2031\n",
      "   macro avg       0.76      0.81      0.75      2031\n",
      "weighted avg       0.84      0.76      0.78      2031\n",
      "\n",
      "for i:  15\n",
      "Accuracy score:  0.758739537173806\n",
      "Confusion matrix:\n",
      " [[1005  434]\n",
      " [  56  536]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.70      0.80      1439\n",
      "           1       0.55      0.91      0.69       592\n",
      "\n",
      "    accuracy                           0.76      2031\n",
      "   macro avg       0.75      0.80      0.75      2031\n",
      "weighted avg       0.83      0.76      0.77      2031\n",
      "\n",
      "for i:  16\n",
      "Accuracy score:  0.758739537173806\n",
      "Confusion matrix:\n",
      " [[1005  434]\n",
      " [  56  536]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.70      0.80      1439\n",
      "           1       0.55      0.91      0.69       592\n",
      "\n",
      "    accuracy                           0.76      2031\n",
      "   macro avg       0.75      0.80      0.75      2031\n",
      "weighted avg       0.83      0.76      0.77      2031\n",
      "\n",
      "for i:  17\n",
      "Accuracy score:  0.758739537173806\n",
      "Confusion matrix:\n",
      " [[1005  434]\n",
      " [  56  536]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.70      0.80      1439\n",
      "           1       0.55      0.91      0.69       592\n",
      "\n",
      "    accuracy                           0.76      2031\n",
      "   macro avg       0.75      0.80      0.75      2031\n",
      "weighted avg       0.83      0.76      0.77      2031\n",
      "\n",
      "for i:  18\n",
      "Accuracy score:  0.758739537173806\n",
      "Confusion matrix:\n",
      " [[1005  434]\n",
      " [  56  536]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.70      0.80      1439\n",
      "           1       0.55      0.91      0.69       592\n",
      "\n",
      "    accuracy                           0.76      2031\n",
      "   macro avg       0.75      0.80      0.75      2031\n",
      "weighted avg       0.83      0.76      0.77      2031\n",
      "\n",
      "for i:  19\n",
      "Accuracy score:  0.7607090103397341\n",
      "Confusion matrix:\n",
      " [[1009  434]\n",
      " [  52  536]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.70      0.81      1443\n",
      "           1       0.55      0.91      0.69       588\n",
      "\n",
      "    accuracy                           0.76      2031\n",
      "   macro avg       0.75      0.81      0.75      2031\n",
      "weighted avg       0.84      0.76      0.77      2031\n",
      "\n",
      "for i:  20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.758739537173806\n",
      "Confusion matrix:\n",
      " [[1005  434]\n",
      " [  56  536]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.70      0.80      1439\n",
      "           1       0.55      0.91      0.69       592\n",
      "\n",
      "    accuracy                           0.76      2031\n",
      "   macro avg       0.75      0.80      0.75      2031\n",
      "weighted avg       0.83      0.76      0.77      2031\n",
      "\n",
      "for i:  21\n",
      "Accuracy score:  0.758739537173806\n",
      "Confusion matrix:\n",
      " [[1005  434]\n",
      " [  56  536]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.70      0.80      1439\n",
      "           1       0.55      0.91      0.69       592\n",
      "\n",
      "    accuracy                           0.76      2031\n",
      "   macro avg       0.75      0.80      0.75      2031\n",
      "weighted avg       0.83      0.76      0.77      2031\n",
      "\n",
      "for i:  22\n",
      "Accuracy score:  0.758739537173806\n",
      "Confusion matrix:\n",
      " [[1005  434]\n",
      " [  56  536]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.70      0.80      1439\n",
      "           1       0.55      0.91      0.69       592\n",
      "\n",
      "    accuracy                           0.76      2031\n",
      "   macro avg       0.75      0.80      0.75      2031\n",
      "weighted avg       0.83      0.76      0.77      2031\n",
      "\n",
      "for i:  23\n",
      "Accuracy score:  0.758739537173806\n",
      "Confusion matrix:\n",
      " [[1005  434]\n",
      " [  56  536]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.70      0.80      1439\n",
      "           1       0.55      0.91      0.69       592\n",
      "\n",
      "    accuracy                           0.76      2031\n",
      "   macro avg       0.75      0.80      0.75      2031\n",
      "weighted avg       0.83      0.76      0.77      2031\n",
      "\n",
      "for i:  24\n",
      "Accuracy score:  0.758739537173806\n",
      "Confusion matrix:\n",
      " [[1005  434]\n",
      " [  56  536]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.70      0.80      1439\n",
      "           1       0.55      0.91      0.69       592\n",
      "\n",
      "    accuracy                           0.76      2031\n",
      "   macro avg       0.75      0.80      0.75      2031\n",
      "weighted avg       0.83      0.76      0.77      2031\n",
      "\n",
      "for i:  25\n",
      "Accuracy score:  0.758739537173806\n",
      "Confusion matrix:\n",
      " [[1005  434]\n",
      " [  56  536]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.70      0.80      1439\n",
      "           1       0.55      0.91      0.69       592\n",
      "\n",
      "    accuracy                           0.76      2031\n",
      "   macro avg       0.75      0.80      0.75      2031\n",
      "weighted avg       0.83      0.76      0.77      2031\n",
      "\n",
      "for i:  26\n",
      "Accuracy score:  0.758739537173806\n",
      "Confusion matrix:\n",
      " [[1005  434]\n",
      " [  56  536]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.70      0.80      1439\n",
      "           1       0.55      0.91      0.69       592\n",
      "\n",
      "    accuracy                           0.76      2031\n",
      "   macro avg       0.75      0.80      0.75      2031\n",
      "weighted avg       0.83      0.76      0.77      2031\n",
      "\n",
      "for i:  27\n",
      "Accuracy score:  0.758739537173806\n",
      "Confusion matrix:\n",
      " [[1005  434]\n",
      " [  56  536]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.70      0.80      1439\n",
      "           1       0.55      0.91      0.69       592\n",
      "\n",
      "    accuracy                           0.76      2031\n",
      "   macro avg       0.75      0.80      0.75      2031\n",
      "weighted avg       0.83      0.76      0.77      2031\n",
      "\n",
      "for i:  28\n",
      "Accuracy score:  0.758739537173806\n",
      "Confusion matrix:\n",
      " [[1005  434]\n",
      " [  56  536]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.70      0.80      1439\n",
      "           1       0.55      0.91      0.69       592\n",
      "\n",
      "    accuracy                           0.76      2031\n",
      "   macro avg       0.75      0.80      0.75      2031\n",
      "weighted avg       0.83      0.76      0.77      2031\n",
      "\n",
      "for i:  29\n",
      "Accuracy score:  0.758739537173806\n",
      "Confusion matrix:\n",
      " [[1005  434]\n",
      " [  56  536]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.70      0.80      1439\n",
      "           1       0.55      0.91      0.69       592\n",
      "\n",
      "    accuracy                           0.76      2031\n",
      "   macro avg       0.75      0.80      0.75      2031\n",
      "weighted avg       0.83      0.76      0.77      2031\n",
      "\n",
      "for i:  30\n",
      "Accuracy score:  0.758739537173806\n",
      "Confusion matrix:\n",
      " [[1005  434]\n",
      " [  56  536]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.70      0.80      1439\n",
      "           1       0.55      0.91      0.69       592\n",
      "\n",
      "    accuracy                           0.76      2031\n",
      "   macro avg       0.75      0.80      0.75      2031\n",
      "weighted avg       0.83      0.76      0.77      2031\n",
      "\n",
      "for i:  31\n",
      "Accuracy score:  0.758739537173806\n",
      "Confusion matrix:\n",
      " [[1005  434]\n",
      " [  56  536]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.70      0.80      1439\n",
      "           1       0.55      0.91      0.69       592\n",
      "\n",
      "    accuracy                           0.76      2031\n",
      "   macro avg       0.75      0.80      0.75      2031\n",
      "weighted avg       0.83      0.76      0.77      2031\n",
      "\n",
      "for i:  32\n",
      "Accuracy score:  0.7607090103397341\n",
      "Confusion matrix:\n",
      " [[1009  434]\n",
      " [  52  536]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.70      0.81      1443\n",
      "           1       0.55      0.91      0.69       588\n",
      "\n",
      "    accuracy                           0.76      2031\n",
      "   macro avg       0.75      0.81      0.75      2031\n",
      "weighted avg       0.84      0.76      0.77      2031\n",
      "\n",
      "for i:  33\n",
      "Accuracy score:  0.758739537173806\n",
      "Confusion matrix:\n",
      " [[1005  434]\n",
      " [  56  536]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.70      0.80      1439\n",
      "           1       0.55      0.91      0.69       592\n",
      "\n",
      "    accuracy                           0.76      2031\n",
      "   macro avg       0.75      0.80      0.75      2031\n",
      "weighted avg       0.83      0.76      0.77      2031\n",
      "\n",
      "for i:  34\n",
      "Accuracy score:  0.758739537173806\n",
      "Confusion matrix:\n",
      " [[1005  434]\n",
      " [  56  536]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.70      0.80      1439\n",
      "           1       0.55      0.91      0.69       592\n",
      "\n",
      "    accuracy                           0.76      2031\n",
      "   macro avg       0.75      0.80      0.75      2031\n",
      "weighted avg       0.83      0.76      0.77      2031\n",
      "\n",
      "for i:  35\n",
      "Accuracy score:  0.758739537173806\n",
      "Confusion matrix:\n",
      " [[1005  434]\n",
      " [  56  536]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.70      0.80      1439\n",
      "           1       0.55      0.91      0.69       592\n",
      "\n",
      "    accuracy                           0.76      2031\n",
      "   macro avg       0.75      0.80      0.75      2031\n",
      "weighted avg       0.83      0.76      0.77      2031\n",
      "\n",
      "for i:  36\n",
      "Accuracy score:  0.7636632200886263\n",
      "Confusion matrix:\n",
      " [[1015  434]\n",
      " [  46  536]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.70      0.81      1449\n",
      "           1       0.55      0.92      0.69       582\n",
      "\n",
      "    accuracy                           0.76      2031\n",
      "   macro avg       0.75      0.81      0.75      2031\n",
      "weighted avg       0.84      0.76      0.77      2031\n",
      "\n",
      "for i:  37\n",
      "Accuracy score:  0.758739537173806\n",
      "Confusion matrix:\n",
      " [[1005  434]\n",
      " [  56  536]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.70      0.80      1439\n",
      "           1       0.55      0.91      0.69       592\n",
      "\n",
      "    accuracy                           0.76      2031\n",
      "   macro avg       0.75      0.80      0.75      2031\n",
      "weighted avg       0.83      0.76      0.77      2031\n",
      "\n",
      "for i:  38\n",
      "Accuracy score:  0.758739537173806\n",
      "Confusion matrix:\n",
      " [[1005  434]\n",
      " [  56  536]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.70      0.80      1439\n",
      "           1       0.55      0.91      0.69       592\n",
      "\n",
      "    accuracy                           0.76      2031\n",
      "   macro avg       0.75      0.80      0.75      2031\n",
      "weighted avg       0.83      0.76      0.77      2031\n",
      "\n",
      "for i:  39\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.758739537173806\n",
      "Confusion matrix:\n",
      " [[1005  434]\n",
      " [  56  536]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.70      0.80      1439\n",
      "           1       0.55      0.91      0.69       592\n",
      "\n",
      "    accuracy                           0.76      2031\n",
      "   macro avg       0.75      0.80      0.75      2031\n",
      "weighted avg       0.83      0.76      0.77      2031\n",
      "\n",
      "for i:  40\n",
      "Accuracy score:  0.758739537173806\n",
      "Confusion matrix:\n",
      " [[1005  434]\n",
      " [  56  536]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.70      0.80      1439\n",
      "           1       0.55      0.91      0.69       592\n",
      "\n",
      "    accuracy                           0.76      2031\n",
      "   macro avg       0.75      0.80      0.75      2031\n",
      "weighted avg       0.83      0.76      0.77      2031\n",
      "\n",
      "for i:  41\n",
      "Accuracy score:  0.758739537173806\n",
      "Confusion matrix:\n",
      " [[1005  434]\n",
      " [  56  536]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.70      0.80      1439\n",
      "           1       0.55      0.91      0.69       592\n",
      "\n",
      "    accuracy                           0.76      2031\n",
      "   macro avg       0.75      0.80      0.75      2031\n",
      "weighted avg       0.83      0.76      0.77      2031\n",
      "\n",
      "for i:  42\n",
      "Accuracy score:  0.758739537173806\n",
      "Confusion matrix:\n",
      " [[1005  434]\n",
      " [  56  536]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.70      0.80      1439\n",
      "           1       0.55      0.91      0.69       592\n",
      "\n",
      "    accuracy                           0.76      2031\n",
      "   macro avg       0.75      0.80      0.75      2031\n",
      "weighted avg       0.83      0.76      0.77      2031\n",
      "\n",
      "for i:  43\n",
      "Accuracy score:  0.758739537173806\n",
      "Confusion matrix:\n",
      " [[1005  434]\n",
      " [  56  536]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.70      0.80      1439\n",
      "           1       0.55      0.91      0.69       592\n",
      "\n",
      "    accuracy                           0.76      2031\n",
      "   macro avg       0.75      0.80      0.75      2031\n",
      "weighted avg       0.83      0.76      0.77      2031\n",
      "\n",
      "for i:  44\n",
      "Accuracy score:  0.758739537173806\n",
      "Confusion matrix:\n",
      " [[1005  434]\n",
      " [  56  536]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.70      0.80      1439\n",
      "           1       0.55      0.91      0.69       592\n",
      "\n",
      "    accuracy                           0.76      2031\n",
      "   macro avg       0.75      0.80      0.75      2031\n",
      "weighted avg       0.83      0.76      0.77      2031\n",
      "\n",
      "for i:  45\n",
      "Accuracy score:  0.7592319054652881\n",
      "Confusion matrix:\n",
      " [[1006  434]\n",
      " [  55  536]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.70      0.80      1440\n",
      "           1       0.55      0.91      0.69       591\n",
      "\n",
      "    accuracy                           0.76      2031\n",
      "   macro avg       0.75      0.80      0.75      2031\n",
      "weighted avg       0.83      0.76      0.77      2031\n",
      "\n",
      "for i:  46\n",
      "Accuracy score:  0.758739537173806\n",
      "Confusion matrix:\n",
      " [[1005  434]\n",
      " [  56  536]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.70      0.80      1439\n",
      "           1       0.55      0.91      0.69       592\n",
      "\n",
      "    accuracy                           0.76      2031\n",
      "   macro avg       0.75      0.80      0.75      2031\n",
      "weighted avg       0.83      0.76      0.77      2031\n",
      "\n",
      "for i:  47\n",
      "Accuracy score:  0.758739537173806\n",
      "Confusion matrix:\n",
      " [[1005  434]\n",
      " [  56  536]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.70      0.80      1439\n",
      "           1       0.55      0.91      0.69       592\n",
      "\n",
      "    accuracy                           0.76      2031\n",
      "   macro avg       0.75      0.80      0.75      2031\n",
      "weighted avg       0.83      0.76      0.77      2031\n",
      "\n",
      "for i:  48\n",
      "Accuracy score:  0.758739537173806\n",
      "Confusion matrix:\n",
      " [[1005  434]\n",
      " [  56  536]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.70      0.80      1439\n",
      "           1       0.55      0.91      0.69       592\n",
      "\n",
      "    accuracy                           0.76      2031\n",
      "   macro avg       0.75      0.80      0.75      2031\n",
      "weighted avg       0.83      0.76      0.77      2031\n",
      "\n",
      "for i:  49\n",
      "Accuracy score:  0.7602166420482521\n",
      "Confusion matrix:\n",
      " [[1008  434]\n",
      " [  53  536]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.70      0.81      1442\n",
      "           1       0.55      0.91      0.69       589\n",
      "\n",
      "    accuracy                           0.76      2031\n",
      "   macro avg       0.75      0.80      0.75      2031\n",
      "weighted avg       0.83      0.76      0.77      2031\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Have to scale the Random Forest as it is overfitting\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "acc_r=[]\n",
    "for i in range(1,50):\n",
    "    print(\"for i: \",i)\n",
    "    ran=RandomForestClassifier(n_estimators=500,random_state=i)\n",
    "    ran.fit(x_scaled,ytrain)\n",
    "    ran_predt=ran.predict(xtest)\n",
    "    ran_acc=accuracy_score(ran_predt,ytest)\n",
    "    acc_r.append(ran_acc)\n",
    "    print(\"Accuracy score: \",ran_acc)\n",
    "    ran_cm=confusion_matrix(ran_predt,ytest)\n",
    "    print(\"Confusion matrix:\\n\",ran_cm)\n",
    "    ran_cr=classification_report(ran_predt,ytest)\n",
    "    print('Classification report:\\n',ran_cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy max:  0.7646479566715904\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy max: \",max(acc_r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7646479566715904\n",
      "0.758739537173806\n"
     ]
    }
   ],
   "source": [
    "print(max(acc_r))\n",
    "print(min(acc_r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.9970457902511078\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1057\n",
      "           1       1.00      0.99      1.00       974\n",
      "\n",
      "    accuracy                           1.00      2031\n",
      "   macro avg       1.00      1.00      1.00      2031\n",
      "weighted avg       1.00      1.00      1.00      2031\n",
      "\n",
      "Confusion matrix:\n",
      " [[1056    1]\n",
      " [   5  969]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "kn=KNeighborsClassifier(n_neighbors=10,weights='distance')\n",
    "kn.fit(xtrain,ytrain)\n",
    "kn_pred=kn.predict(xtest)\n",
    "kn_acc=accuracy_score(kn_pred,ytest)\n",
    "print(\"Accuracy score: \",kn_acc)\n",
    "kn_cr=classification_report(kn_pred,ytest)\n",
    "print(\"Classification report:\\n\",kn_cr)\n",
    "kn_cm=confusion_matrix(kn_pred,ytest)\n",
    "print(\"Confusion matrix:\\n\",kn_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error:  [0.0004923682914820286, 0.0004923682914820286, 0.0009847365829640572, 0.0019694731659281144, 0.0019694731659281144, 0.0029542097488921715, 0.002461841457410143, 0.002461841457410143, 0.0019694731659281144, 0.0029542097488921715, 0.0014771048744460858, 0.0029542097488921715, 0.002461841457410143, 0.0034465780403741997, 0.0029542097488921715, 0.003938946331856229, 0.003938946331856229, 0.004431314623338257, 0.003938946331856229, 0.004431314623338257, 0.004431314623338257, 0.0054160512063023145, 0.0054160512063023145, 0.005908419497784343, 0.0054160512063023145, 0.006400787789266372, 0.006400787789266372, 0.006893156080748399, 0.006400787789266372, 0.007385524372230428, 0.007385524372230428, 0.008370260955194485, 0.0103397341211226, 0.0103397341211226, 0.011324470704086657, 0.011324470704086657, 0.012801575578532743, 0.012801575578532743, 0.014771048744460856]\n"
     ]
    }
   ],
   "source": [
    "# Error rate for K-value\n",
    "error=[]\n",
    "for i in range(1,40):\n",
    "    kn=KNeighborsClassifier(n_neighbors=i,weights='distance')\n",
    "    kn.fit(xtrain,ytrain)\n",
    "    kn_predt=kn.predict(xtest)\n",
    "    error.append(np.mean(kn_predt!=ytest))    \n",
    "print(\"error: \",error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Mean errors')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "dark"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(range(1,40),error,linestyle='dashed',marker='o',markersize=10)\n",
    "plt.title(\"Error rate for K-value\")\n",
    "plt.xlabel(\"K values\")\n",
    "plt.ylabel(\"Mean errors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for k value 1,2 KNN gives more accuracy and less error rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.9985228951255539\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1058\n",
      "           1       1.00      1.00      1.00       973\n",
      "\n",
      "    accuracy                           1.00      2031\n",
      "   macro avg       1.00      1.00      1.00      2031\n",
      "weighted avg       1.00      1.00      1.00      2031\n",
      "\n",
      "Confusion matrix:\n",
      " [[1058    0]\n",
      " [   3  970]]\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "kn=KNeighborsClassifier(n_neighbors=11,weights='distance')\n",
    "kn.fit(xtrain,ytrain)\n",
    "kn_pred=kn.predict(xtest)\n",
    "kn_acc1=accuracy_score(kn_pred,ytest)\n",
    "print(\"Accuracy score: \",kn_acc1)\n",
    "kn_cr=classification_report(kn_pred,ytest)\n",
    "print(\"Classification report:\\n\",kn_cr)\n",
    "kn_cm=confusion_matrix(kn_pred,ytest)\n",
    "print(\"Confusion matrix:\\n\",kn_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.9103889709502708\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "sv=SVC(kernel='linear',C=0.001)\n",
    "sv.fit(xtrain,ytrain)\n",
    "sv_predt=sv.predict(xtest)\n",
    "sv_acc=accuracy_score(sv_predt,ytest)\n",
    "print(\"Accuracy score: \",sv_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index           Algorithms  Accuracy\n",
      "0      3                  KNN  0.998523\n",
      "1      0  Logistic Regression  0.947317\n",
      "2      4                  SVM  0.910389\n",
      "3      2        Random Forest  0.764648\n",
      "4      1        Decision Tree  0.522403\n"
     ]
    }
   ],
   "source": [
    "df1={\"Algorithms\":['Logistic Regression','Decision Tree','Random Forest','KNN','SVM'],\n",
    "    \"Accuracy\":[max(ac),max(acc),max(acc_r),kn_acc1,sv_acc]}\n",
    "df1=pd.DataFrame(df1)\n",
    "print(df1.sort_values(by='Accuracy',ascending=False).reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
